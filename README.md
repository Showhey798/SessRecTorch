# セッションベース推薦システムにおけるオフライン強化学習について

## 背景
従来のセッションベース推薦システムはNext Item Recommendationと呼ばれることが多く過去のセッション履歴からユーザが次にクリックしそうなアイテムを推薦するタスクを解いてきた．一方で，近年のサービスはサブスクリプション等の導入により，単にユーザがクリックしたくなるアイテムを推薦するだけでなくユーザにそのサービスを継続してもらうことも重要視されている．つまり，ユーザが長期的に利用を続けてくれるような推薦が求められている．
例えば，過去の履歴からそのユーザが好みそうなアイテムを推薦し続けると動画配信やニュースといったアイテムの消費サイクルが早い分野ではいずれ飽きがきてしまいユーザがサービスを離れてしまう可能性が高まる．

近年ユーザが長期的に利用するような推薦を可能にするために強化学習の適用が検討されている．
しかし，強化学習を推薦システムに応用する際にいくつか課題が存在する。
例えば，
- 強化学習は実際の環境とインタラクションを通じて最適化を行うが実際の環境に導入するにはコストがかかる点
- 過去成功してきた分野（ロボットやゲーム）では行動空間が少ないため行動空間の広い推薦システムでは成功が保証されていない点


## オフライン強化学習について
